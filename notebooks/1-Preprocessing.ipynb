{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import geopandas as gpd\n",
    "\n",
    "from scripts import preprocessing as pre\n",
    "\n",
    "from config import Preprocessing\n",
    "config = reload(Preprocessing).Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training area and training polygons\n",
    "trainingArea = gpd.read_file(config.training_base_dir/config.training_area_fn)\n",
    "trainingPolygon = gpd.read_file(config.training_base_dir/config.training_polygon_fn)\n",
    "\n",
    "print(\n",
    "    f\"Read a total of {trainingPolygon.shape[0]} object polygons and \"\n",
    "    \"{trainingArea.shape[0]} training areas.\"\n",
    ")\n",
    "print(f\"Polygons will be assigned to training areas in the next steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the training areas and the training polygons have the same crs\n",
    "if trainingArea.crs != trainingPolygon.crs:\n",
    "    print(\"Training area CRS does not match training_polygon CRS\")\n",
    "    # Areas are less in number so conversion should be faster\n",
    "    targetCRS = trainingPolygon.crs  \n",
    "    trainingArea = trainingArea.to_crs(targetCRS)\n",
    "    \n",
    "print(trainingPolygon.crs)\n",
    "print(trainingArea.crs)\n",
    "assert trainingPolygon.crs == trainingArea.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign serial IDs to training areas and polygons\n",
    "trainingArea[\"id\"] = range(trainingArea.shape[0])\n",
    "trainingPolygon[\"id\"] = range(trainingPolygon.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# areasWithPolygons contains the object polygons and weighted boundaries for each area!\n",
    "areas_with_polygons = pre.dividePolygonsInTrainingAreas(trainingPolygon, trainingArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = reload(Preprocessing).Configuration()\n",
    "input_images = pre.read_input_images(\n",
    "    config.raw_image_base_dir,\n",
    "    config.raw_image_file_type,\n",
    "    config.raw_image_suffix,\n",
    ")\n",
    "print(f\"Found a total of {len(input_images)} pair of raw image(s) to process!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = reload(pre)\n",
    "config = reload(Preprocessing).Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main function for extracting part of ndvi and \n",
    "# pan images that overlap with training areas\n",
    "pre.findOverlap(\n",
    "    input_images,\n",
    "    areas_with_polygons,\n",
    "    config.path_to_write,\n",
    "    config.extracted_bands_folder,\n",
    "    config.extracted_annotation_folder,\n",
    "    config.extracted_boundary_folder,\n",
    "    config.bands,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted image\n",
    "sampleImage = \"_0.png\"\n",
    "fn = config.path_to_write/config.extracted_ndvi_filename/sampleImage\n",
    "\n",
    "ndvi_img = Image.open(fn)\n",
    "pan_img = Image.open(\n",
    "    fn.replace(config.extracted_ndvi_filename, config.extracted_pan_filename)\n",
    ")\n",
    "read_ndvi_img = np.array(ndvi_img)\n",
    "read_pan_img = np.array(pan_img)\n",
    "annotation_im = Image.open(\n",
    "    fn.replace(config.extracted_ndvi_filename, config.extracted_annotation_filename)\n",
    ")\n",
    "read_annotation = np.array(annotation_im)\n",
    "weight_im = Image.open(\n",
    "    fn.replace(config.extracted_ndvi_filename, config.extracted_boundary_filename)\n",
    ")\n",
    "read_weight = np.array(weight_im)\n",
    "all_images = np.array([read_ndvi_img, read_pan_img, read_annotation, read_weight])\n",
    "\n",
    "display_images(np.expand_dims(np.transpose(all_images, axes=(1, 2, 0)), axis=0))\n",
    "# plt.imshow(read_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
