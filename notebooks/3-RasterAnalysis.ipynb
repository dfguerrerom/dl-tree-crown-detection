{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Edited by Sizhuo Li\n",
    "   \n",
    "   Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adadelta.py:74: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adadelta, self).__init__(name, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/nadam.py:73: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Nadam, self).__init__(name, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adagrad.py:74: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adagrad, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio  # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp  # Reproject raster samples\n",
    "from rasterio import windows\n",
    "import fiona  # I/O vector data (shape, geojson, ...)\n",
    "\n",
    "from shapely.geometry import Polygon, mapping\n",
    "\n",
    "import numpy as np  # numerical array manipulation\n",
    "from tqdm import tqdm\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "\n",
    "from itertools import product\n",
    "from tensorflow.keras.models import load_model\n",
    "from core.losses import (\n",
    "    tversky,\n",
    "    accuracy,\n",
    "    dice_coef,\n",
    "    dice_loss,\n",
    "    specificity,\n",
    "    sensitivity,\n",
    ")\n",
    "from core.optimizers import adaDelta\n",
    "from core.frame_info import  image_normalize\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import warnings  # ignore annoying warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from config import RasterAnalysis as config\n",
    "\n",
    "config = reload(config)\n",
    "config = config.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 15:47:35.515298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:35.524864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:35.525182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:35.526230: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-25 15:47:35.526723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:35.527049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:35.527316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:36.125898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:36.126263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:36.126602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:47:36.126844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 208 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "2022-05-25 15:47:36.130477: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 208.75M (218890240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-05-25 15:47:46.211660: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.00MiB (rounded to 37748736)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-05-25 15:47:46.211707: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-05-25 15:47:46.211718: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 28, Chunks in use: 28. 7.0KiB allocated for chunks. 7.0KiB in use in bin. 1.6KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211726: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 7, Chunks in use: 6. 3.8KiB allocated for chunks. 3.0KiB in use in bin. 3.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211733: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211741: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 6, Chunks in use: 6. 12.0KiB allocated for chunks. 12.0KiB in use in bin. 12.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211748: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211755: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 9.0KiB allocated for chunks. 9.0KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211762: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211769: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211775: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211784: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 1, Chunks in use: 1. 144.0KiB allocated for chunks. 144.0KiB in use in bin. 144.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211791: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 3, Chunks in use: 1. 850.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211799: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 576.0KiB allocated for chunks. 576.0KiB in use in bin. 576.0KiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211807: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 1. 3.38MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211818: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 1, Chunks in use: 1. 2.25MiB allocated for chunks. 2.25MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211828: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 3, Chunks in use: 1. 13.50MiB allocated for chunks. 4.50MiB in use in bin. 4.50MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211837: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 1, Chunks in use: 1. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211847: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 3, Chunks in use: 1. 54.00MiB allocated for chunks. 18.00MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211857: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 36.00MiB allocated for chunks. 36.00MiB in use in bin. 36.00MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211870: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 68.17MiB allocated for chunks. 68.17MiB in use in bin. 36.00MiB client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211878: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211887: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-05-25 15:47:46.211898: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 36.00MiB was 32.00MiB, Chunk State: \n",
      "2022-05-25 15:47:46.211906: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 197001216\n",
      "2022-05-25 15:47:46.211919: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000000 of size 1280 next 1\n",
      "2022-05-25 15:47:46.211927: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000500 of size 256 next 2\n",
      "2022-05-25 15:47:46.211935: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000600 of size 256 next 3\n",
      "2022-05-25 15:47:46.211942: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000700 of size 256 next 4\n",
      "2022-05-25 15:47:46.211950: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000800 of size 256 next 5\n",
      "2022-05-25 15:47:46.211958: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000900 of size 256 next 8\n",
      "2022-05-25 15:47:46.211966: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000a00 of size 256 next 9\n",
      "2022-05-25 15:47:46.211974: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000b00 of size 256 next 10\n",
      "2022-05-25 15:47:46.211982: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000c00 of size 256 next 13\n",
      "2022-05-25 15:47:46.211990: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000d00 of size 256 next 14\n",
      "2022-05-25 15:47:46.211997: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000e00 of size 256 next 15\n",
      "2022-05-25 15:47:46.212005: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0000f00 of size 256 next 16\n",
      "2022-05-25 15:47:46.212013: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001000 of size 256 next 17\n",
      "2022-05-25 15:47:46.212021: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001100 of size 256 next 18\n",
      "2022-05-25 15:47:46.212028: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001200 of size 256 next 19\n",
      "2022-05-25 15:47:46.212037: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001300 of size 512 next 22\n",
      "2022-05-25 15:47:46.212044: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001500 of size 256 next 23\n",
      "2022-05-25 15:47:46.212052: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001600 of size 256 next 24\n",
      "2022-05-25 15:47:46.212060: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001700 of size 512 next 25\n",
      "2022-05-25 15:47:46.212067: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001900 of size 512 next 28\n",
      "2022-05-25 15:47:46.212074: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001b00 of size 512 next 29\n",
      "2022-05-25 15:47:46.212082: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001d00 of size 512 next 30\n",
      "2022-05-25 15:47:46.212113: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0001f00 of size 512 next 31\n",
      "2022-05-25 15:47:46.212123: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002100 of size 256 next 32\n",
      "2022-05-25 15:47:46.212135: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002200 of size 256 next 33\n",
      "2022-05-25 15:47:46.212143: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002300 of size 1024 next 36\n",
      "2022-05-25 15:47:46.212156: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002700 of size 256 next 37\n",
      "2022-05-25 15:47:46.212168: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002800 of size 256 next 38\n",
      "2022-05-25 15:47:46.212177: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002900 of size 1024 next 39\n",
      "2022-05-25 15:47:46.212195: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0002d00 of size 1024 next 42\n",
      "2022-05-25 15:47:46.212202: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003100 of size 1024 next 43\n",
      "2022-05-25 15:47:46.212210: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003500 of size 1024 next 44\n",
      "2022-05-25 15:47:46.212221: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003900 of size 1024 next 45\n",
      "2022-05-25 15:47:46.212233: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003d00 of size 256 next 46\n",
      "2022-05-25 15:47:46.212241: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003e00 of size 256 next 47\n",
      "2022-05-25 15:47:46.212252: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0003f00 of size 2048 next 50\n",
      "2022-05-25 15:47:46.212260: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004700 of size 256 next 51\n",
      "2022-05-25 15:47:46.212268: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004800 of size 256 next 52\n",
      "2022-05-25 15:47:46.212276: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004900 of size 256 next 60\n",
      "2022-05-25 15:47:46.212284: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004a00 of size 256 next 61\n",
      "2022-05-25 15:47:46.212295: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004b00 of size 256 next 65\n",
      "2022-05-25 15:47:46.212304: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0004c00 of size 256 next 66\n",
      "2022-05-25 15:47:46.212315: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e0004d00 of size 768 next 6\n",
      "2022-05-25 15:47:46.212324: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0005000 of size 9216 next 7\n",
      "2022-05-25 15:47:46.212336: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0007400 of size 2048 next 53\n",
      "2022-05-25 15:47:46.212345: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0007c00 of size 2048 next 56\n",
      "2022-05-25 15:47:46.212356: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0008400 of size 2048 next 57\n",
      "2022-05-25 15:47:46.212364: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0008c00 of size 2048 next 58\n",
      "2022-05-25 15:47:46.212373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0009400 of size 2048 next 59\n",
      "2022-05-25 15:47:46.212382: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0009c00 of size 4096 next 64\n",
      "2022-05-25 15:47:46.212390: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e000ac00 of size 280576 next 12\n",
      "2022-05-25 15:47:46.212400: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e004f400 of size 147456 next 11\n",
      "2022-05-25 15:47:46.212408: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e0073400 of size 294912 next 21\n",
      "2022-05-25 15:47:46.212419: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e00bb400 of size 294912 next 20\n",
      "2022-05-25 15:47:46.212427: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e0103400 of size 1179648 next 27\n",
      "2022-05-25 15:47:46.212436: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0223400 of size 589824 next 26\n",
      "2022-05-25 15:47:46.212445: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e02b3400 of size 1179648 next 35\n",
      "2022-05-25 15:47:46.212455: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e03d3400 of size 1179648 next 34\n",
      "2022-05-25 15:47:46.212463: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e04f3400 of size 4718592 next 41\n",
      "2022-05-25 15:47:46.212472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e0973400 of size 2359296 next 40\n",
      "2022-05-25 15:47:46.212483: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e0bb3400 of size 4718592 next 49\n",
      "2022-05-25 15:47:46.212491: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e1033400 of size 4718592 next 48\n",
      "2022-05-25 15:47:46.212500: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e14b3400 of size 18874368 next 55\n",
      "2022-05-25 15:47:46.212510: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e26b3400 of size 9437184 next 54\n",
      "2022-05-25 15:47:46.212519: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7fd1e2fb3400 of size 18874368 next 63\n",
      "2022-05-25 15:47:46.212539: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e41b3400 of size 18874368 next 62\n",
      "2022-05-25 15:47:46.212552: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e53b3400 of size 37748736 next 67\n",
      "2022-05-25 15:47:46.212562: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7fd1e77b3400 of size 71486464 next 18446744073709551615\n",
      "2022-05-25 15:47:46.212570: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-05-25 15:47:46.212586: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 28 Chunks of size 256 totalling 7.0KiB\n",
      "2022-05-25 15:47:46.212643: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 512 totalling 3.0KiB\n",
      "2022-05-25 15:47:46.212690: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 1024 totalling 6.0KiB\n",
      "2022-05-25 15:47:46.212707: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-05-25 15:47:46.212718: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 6 Chunks of size 2048 totalling 12.0KiB\n",
      "2022-05-25 15:47:46.212727: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2022-05-25 15:47:46.212748: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9216 totalling 9.0KiB\n",
      "2022-05-25 15:47:46.212758: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 147456 totalling 144.0KiB\n",
      "2022-05-25 15:47:46.212768: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2022-05-25 15:47:46.212778: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2022-05-25 15:47:46.212788: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2022-05-25 15:47:46.212797: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 2359296 totalling 2.25MiB\n",
      "2022-05-25 15:47:46.212806: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 4718592 totalling 4.50MiB\n",
      "2022-05-25 15:47:46.212836: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9437184 totalling 9.00MiB\n",
      "2022-05-25 15:47:46.212844: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 18874368 totalling 18.00MiB\n",
      "2022-05-25 15:47:46.212853: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 37748736 totalling 36.00MiB\n",
      "2022-05-25 15:47:46.212860: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 71486464 totalling 68.17MiB\n",
      "2022-05-25 15:47:46.212867: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 140.08MiB\n",
      "2022-05-25 15:47:46.212879: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 197001216 memory_limit_: 218890240 available bytes: 21889024 curr_region_allocation_bytes_: 437780480\n",
      "2022-05-25 15:47:46.212890: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                       218890240\n",
      "InUse:                       146879744\n",
      "MaxInUse:                    146880000\n",
      "NumAllocs:                          87\n",
      "MaxAllocSize:                 71486464\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-25 15:47:46.212902: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ***__**_****________******________*************************************************xxxxxxxxxxxxxxxxx\n",
      "2022-05-25 15:47:46.215225: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get the last model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(config\u001b[38;5;241m.\u001b[39mmodel_path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtversky\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtversky\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdice_coef\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdice_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdice_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdice_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecificity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecificity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msensitivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msensitivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mOPTIMIZER,\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtversky,\n\u001b[1;32m     21\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[dice_coef, dice_loss, accuracy, specificity, sensitivity],\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py:1831\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator:\n\u001b[1;32m   1829\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m   1830\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape, minval\u001b[38;5;241m=\u001b[39mminval, maxval\u001b[38;5;241m=\u001b[39mmaxval, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m-> 1831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_legacy_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# Load a pretrained model\n",
    "OPTIMIZER = adaDelta\n",
    "\n",
    "# Get the last model\n",
    "model_path = list(config.model_path.glob(\"*.h5\"))[-1]\n",
    "model = load_model(\n",
    "    model_path,\n",
    "    custom_objects={\n",
    "        \"tversky\": tversky,\n",
    "        \"dice_coef\": dice_coef,\n",
    "        \"dice_loss\": dice_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"specificity\": specificity,\n",
    "        \"sensitivity\": sensitivity,\n",
    "    },\n",
    "    compile=False,\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=OPTIMIZER,\n",
    "    loss=tversky,\n",
    "    metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to add results of a patch to the total results of a larger area. \n",
    "# The operator could be min (useful if there are too many false positives), max (useful for tackle false negatives)\n",
    "def addTOResult(res, prediction, row, col, he, wi, operator=\"MAX\"):\n",
    "    currValue = res[row : row + he, col : col + wi]\n",
    "    newPredictions = prediction[:he, :wi]\n",
    "    # IMPORTANT: MIN can't be used as long as the mask is initialed with 0!!!!! \n",
    "    # If you want to use MIN initial the mask with -1 and handle the case of default value(-1) separately.\n",
    "    if (\n",
    "        operator == \"MIN\"\n",
    "    ):  # Takes the min of current prediction and new prediction for each pixel\n",
    "        currValue[currValue == -1] = 1  # Replace -1 with 1 in case of MIN\n",
    "        resultant = np.minimum(currValue, newPredictions)\n",
    "    elif operator == \"MAX\":\n",
    "        resultant = np.maximum(currValue, newPredictions)\n",
    "    else:  # operator == 'REPLACE':\n",
    "        resultant = newPredictions\n",
    "    # Alternative approach; Lets assume that quality of prediction is better in the centre of the image than on the edges\n",
    "    # We use numbers from 1-5 to denote the quality, where 5 is the best and 1 is the worst.In that case, the best result would be to take into quality of prediction based upon position in account\n",
    "    # So for merge with stride of 0.5, for eg. [12345432100000] AND [00000123454321], should be [1234543454321] instead of [1234543214321] that you will currently get.\n",
    "    # However, in case the values are strecthed before hand this problem will be minimized\n",
    "    res[row : row + he, col : col + wi] = resultant\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods that actually makes the predictions\n",
    "def predict_using_model(model, batch, batch_pos, mask, operator):\n",
    "    tm = np.stack(batch, axis=0)\n",
    "    prediction = model.predict(tm)\n",
    "    for i in range(len(batch_pos)):\n",
    "        (col, row, wi, he) = batch_pos[i]\n",
    "        p = np.squeeze(prediction[i], axis=-1)\n",
    "        # Instead of replacing the current values with new values, use the user specified operator (MIN,MAX,REPLACE)\n",
    "        mask = addTOResult(mask, p, row, col, he, wi, operator)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def detect_tree(ndvi_img, pan_img, width=256, height=256, stride=128, normalize=True):\n",
    "    assert (\n",
    "        ndvi_img.meta[\"width\"] == pan_img.meta[\"width\"]\n",
    "        and ndvi_img.meta[\"height\"] == pan_img.meta[\"height\"]\n",
    "    )\n",
    "    nols, nrows = ndvi_img.meta[\"width\"], ndvi_img.meta[\"height\"]\n",
    "    meta = ndvi_img.meta.copy()\n",
    "    if (\n",
    "        \"float\" not in meta[\"dtype\"]\n",
    "    ):  # The prediction is a float so we keep it as float to be consistent with the prediction.\n",
    "        meta[\"dtype\"] = np.float32\n",
    "    offsets = product(range(0, nols, stride), range(0, nrows, stride))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    #     print(nrows, nols)\n",
    "\n",
    "    mask = np.zeros((nrows, nols), dtype=meta[\"dtype\"])\n",
    "\n",
    "    #     mask = mask -1 # Note: The initial mask is initialized with -1 instead of zero to handle the MIN case (see addToResult)\n",
    "    batch = []\n",
    "    batch_pos = []\n",
    "    for col_off, row_off in tqdm(offsets):\n",
    "        window = windows.Window(\n",
    "            col_off=col_off, row_off=row_off, width=width, height=height\n",
    "        ).intersection(big_window)\n",
    "        transform = windows.transform(window, ndvi_img.transform)\n",
    "        patch = np.zeros(\n",
    "            (height, width, 2)\n",
    "        )  # Add zero padding in case of corner images\n",
    "        ndvi_sm = ndvi_img.read(window=window)\n",
    "        pan_sm = pan_img.read(window=window)\n",
    "        temp_im = np.stack((ndvi_sm, pan_sm), axis=-1)\n",
    "        temp_im = np.squeeze(temp_im)\n",
    "\n",
    "        if normalize:\n",
    "            temp_im = image_normalize(\n",
    "                temp_im, axis=(0, 1)\n",
    "            )  # Normalize the image along the width and height i.e. independently per channel\n",
    "\n",
    "        patch[: window.height, : window.width] = temp_im\n",
    "        batch.append(patch)\n",
    "        batch_pos.append((window.col_off, window.row_off, window.width, window.height))\n",
    "        if len(batch) == config.BATCH_SIZE:\n",
    "            mask = predict_using_model(model, batch, batch_pos, mask, \"MAX\")\n",
    "            batch = []\n",
    "            batch_pos = []\n",
    "\n",
    "    # To handle the edge of images as the image size may not be divisible by n complete batches and few frames on the edge may be left.\n",
    "    if batch:\n",
    "        mask = predict_using_model(model, batch, batch_pos, mask, \"MAX\")\n",
    "        batch = []\n",
    "        batch_pos = []\n",
    "\n",
    "    return (mask, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"geometry\": \"Polygon\",\n",
    "    \"properties\": {\n",
    "        \"id\": \"str\",\n",
    "        \"canopy\": \"float:15.2\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def drawPolygons(polygons, shape):\n",
    "    mask = np.zeros(shape, dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    for polygon in polygons:\n",
    "        xy = [(point[1], point[0]) for point in polygon]\n",
    "        draw.polygon(xy=xy, outline=255, fill=255)\n",
    "    mask = np.array(mask)  # , dtype=bool)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def transformToXY(polygons, transform):\n",
    "    tp = []\n",
    "    for polygon in polygons:\n",
    "        rows, cols = zip(*polygon)\n",
    "        x, y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tp.append(list(zip(x, y)))\n",
    "    return tp\n",
    "\n",
    "\n",
    "def createShapefileObject(polygons, meta, wfile):\n",
    "    with fiona.open(\n",
    "        wfile,\n",
    "        \"w\",\n",
    "        crs=meta.get(\"crs\").to_dict(),\n",
    "        driver=\"ESRI Shapefile\",\n",
    "        schema=schema,\n",
    "    ) as sink:\n",
    "        for idx, mp in enumerate(polygons):\n",
    "            try:\n",
    "                #                 poly = Polygon(poly)\n",
    "                #             assert mp.is_valid\n",
    "                #             assert mp.geom_type == 'Polygon'\n",
    "                sink.write(\n",
    "                    {\n",
    "                        \"geometry\": mapping(mp),\n",
    "                        \"properties\": {\"id\": str(idx), \"canopy\": mp.area},\n",
    "                    }\n",
    "                )\n",
    "            except:\n",
    "                print(\n",
    "                    \"An exception occurred in createShapefileObject; Polygon must have more than 2 points\"\n",
    "                )\n",
    "\n",
    "\n",
    "#                 print(mp)\n",
    "\n",
    "# Generate a mask with polygons\n",
    "def transformContoursToXY(contours, transform=None):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x, y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return tp\n",
    "\n",
    "\n",
    "def mask_to_polygons(maskF, transform):\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    th = 0.5\n",
    "    mask = maskF.copy()\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Convert contours from image coordinate to xy coordinate\n",
    "    contours = transformContoursToXY(contours, transform)\n",
    "    if not contours:  # TODO: Raise an error maybe\n",
    "        print(\"Warning: No contours/polygons detected!!\")\n",
    "        return [Polygon()]\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if (\n",
    "            idx not in child_contours\n",
    "        ):  # and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(shell=cnt, holes=[c for c in cnt_children.get(idx, [])])\n",
    "                # if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except:\n",
    "                pass\n",
    "    #                 print(\"An exception occurred in createShapefileObject; Polygon must have more than 2 points\")\n",
    "    print(len(all_polygons))\n",
    "    return all_polygons\n",
    "\n",
    "\n",
    "def create_contours_shapefile(mask, meta, out_fn):\n",
    "    res = mask_to_polygons(mask, meta[\"transform\"])\n",
    "    #     res = transformToXY(contours, meta['transform'])\n",
    "    createShapefileObject(res, meta, out_fn)\n",
    "\n",
    "\n",
    "def writeMaskToDisk(\n",
    "    detected_mask,\n",
    "    detected_meta,\n",
    "    wp,\n",
    "    write_as_type=\"uint8\",\n",
    "    th=0.5,\n",
    "    create_countors=False,\n",
    "):\n",
    "    # Convert to correct required before writing\n",
    "    if \"float\" in str(detected_meta[\"dtype\"]) and \"int\" in write_as_type:\n",
    "        print(\n",
    "            f'Converting prediction from {detected_meta[\"dtype\"]} to {write_as_type}, using threshold of {th}'\n",
    "        )\n",
    "        detected_mask[detected_mask < th] = 0\n",
    "        detected_mask[detected_mask >= th] = 1\n",
    "        detected_mask = detected_mask.astype(write_as_type)\n",
    "        detected_meta[\"dtype\"] = write_as_type\n",
    "\n",
    "    with rasterio.open(wp, \"w\", **detected_meta) as outds:\n",
    "        outds.write(detected_mask, 1)\n",
    "    if create_countors:\n",
    "        wp = wp.replace(image_type, output_shapefile_type)\n",
    "        create_contours_shapefile(detected_mask, detected_meta, wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict trees in the all the files in the input image dir\n",
    "# Depending upon the available RAM, images may not to be split before running this cell.\n",
    "# Use the Auxiliary-2-SplitRasterToAnalyse if the images are too big to be analysed in memory.\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(config.input_image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(config.input_image_type) and file.startswith(\n",
    "            config.ndvi_fn_st\n",
    "        ):\n",
    "            all_files.append((os.path.join(root, file), file))\n",
    "# print(all_files)\n",
    "for fullPath, filename in all_files:\n",
    "    outputFile = os.path.join(\n",
    "        config.output_dir, filename.replace(config.ndvi_fn_st, config.output_prefix)\n",
    "    )\n",
    "    if not os.path.isfile(outputFile) or config.overwrite_analysed_files:\n",
    "        with rasterio.open(fullPath) as ndvi:\n",
    "            with rasterio.open(\n",
    "                fullPath.replace(config.ndvi_fn_st, config.pan_fn_st)\n",
    "            ) as pan:\n",
    "                print(fullPath)\n",
    "                detectedMask, detectedMeta = detect_tree(\n",
    "                    ndvi,\n",
    "                    pan,\n",
    "                    width=config.WIDTH,\n",
    "                    height=config.HEIGHT,\n",
    "                    stride=config.STRIDE,\n",
    "                )  # WIDTH and HEIGHT should be the same and in this case Stride is 50 % width\n",
    "                # Write the mask to file\n",
    "                writeMaskToDisk(\n",
    "                    detectedMask,\n",
    "                    detectedMeta,\n",
    "                    outputFile,\n",
    "                    write_as_type=config.output_dtype,\n",
    "                    th=0.5,\n",
    "                    create_countors=False,\n",
    "                )\n",
    "    else:\n",
    "        print(\"File already analysed!\", fullPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display extracted image\n",
    "sampleImage = \"\"\n",
    "fn = os.path.join(config.output_dir, config.output_prefix + sampleImage)\n",
    "predicted_img = rasterio.open(fn)\n",
    "p = predicted_img.read()\n",
    "np.unique(p, return_counts=True)\n",
    "plt.imshow(p[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
